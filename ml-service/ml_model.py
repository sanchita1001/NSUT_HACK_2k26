# -*- coding: utf-8 -*-
"""ML_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bUn1eKdvV_RIeKqf1NT9fKlGcD7Oq21k

#Dataset Feature Extraction and Libraries
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import IsolationForest



from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn
import os
import json
from fastapi import FastAPI, HTTPException
from sklearn.preprocessing import LabelEncoder
import math

app = FastAPI()

# Global API Model Variables (from service.py)
api_model = None
encoders = {}
data_stats = {}

class Transaction(BaseModel):
    amount: float
    agency: str
    vendor: str
    transaction_time: str = None  # Optional: HH:MM format

# ===== FEATURE 5: BENFORD'S LAW =====
def check_benfords_law(amount):
    """Check if first digit follows Benford's Law distribution"""
    if amount < 10:
        return 0, ""
    
    first_digit = int(str(int(amount))[0])
    # Benford's Law: digits 1-3 are most common, 8-9 are rare
    if first_digit >= 8:
        return 15, f"First digit ({first_digit}) violates Benford's Law (rare in natural data)"
    return 0, ""

# ===== FEATURE 7: TIME-BASED ANOMALY DETECTION =====
def check_transaction_time(transaction_time):
    """Flag transactions outside normal business hours"""
    if not transaction_time:
        return 0, ""
    
    try:
        hour = int(transaction_time.split(':')[0])
        # Flag transactions between 10 PM and 6 AM
        if hour < 6 or hour >= 22:
            return 20, f"Transaction at unusual time ({transaction_time})"
        # Flag weekend/late evening (6 PM - 10 PM)
        if hour >= 18:
            return 10, f"Transaction during late hours ({transaction_time})"
    except:
        pass
    
    return 0, ""

# Legacy Notebook Code - Disabled for API Stability
if False: # Change to True if you want to run EDA/Training script manually
    if os.path.exists("government-procurement-via-gebiz.csv"):
        df = pd.read_csv('government-procurement-via-gebiz.csv')
    else:
        # Create empty DF or handle error gracefully if file is missing during dev
        print("Warning: Dataset not found. Using empty placeholder.")
        df = pd.DataFrame(columns=["awarded_amt", "supplier_name", "agency", "award_date"])

# LEGACY CODE COMMENTED OUT FOR STABILITY
# ... (This logic is redundant as API re-trains its own model on startup)
# ...

# ----------------------------------------------------------------------------------
# API LOGIC
# ----------------------------------------------------------------------------------

import traceback

@app.on_event("startup")
def load_and_train_api_model():
    # ... (same as before)
    global api_model, encoders, data_stats
    print("Loading API dataset...")
    try:
        # Load the user's CSV
        if os.path.exists("government-procurement-via-gebiz.csv"):
             df_api = pd.read_csv("government-procurement-via-gebiz.csv")
        else:
             print("Warning: API Dataset not found. Using minimal placeholder logic.")
             df_api = pd.DataFrame(columns=["awarded_amt", "agency", "supplier_name"])
             df_api.loc[0] = [1000, "Unknown", "Unknown"]

        # Preprocessing
        if df_api['awarded_amt'].dtype == object:
           df_api['awarded_amt'] = df_api['awarded_amt'].str.replace('$', '').str.replace(',', '').astype(float)

        # 1. Agency Encoding (Context)
        le_agency = LabelEncoder()
        df_api['agency'] = df_api['agency'].astype(str).fillna('Unknown')
        df_api['encoded_agency'] = le_agency.fit_transform(df_api['agency'])
        encoders['agency'] = le_agency

        print(f"API Model: Training on {len(df_api)} records with {len(le_agency.classes_)} agencies...")

        # 2. Train Context-Aware Model
        X_api = df_api[['awarded_amt', 'encoded_agency']].values
        api_model = IsolationForest(contamination=0.02, random_state=42, n_estimators=200)
        api_model.fit(X_api)

        # 3. Compute Statistical Baselines
        agency_stats = df_api.groupby('agency')['awarded_amt'].agg(['mean', 'std', 'max']).to_dict('index')
        data_stats['agency_stats'] = agency_stats
        data_stats['global_mean'] = df_api['awarded_amt'].mean()
        data_stats['global_99th'] = df_api['awarded_amt'].quantile(0.99)

        print("API Model (Ironclad) Trained Successfully!")

    except Exception as e:
        print(f"Error training API model: {e}")
        api_model = IsolationForest(contamination=0.1)
        api_model.fit(np.array([[1000, 0], [5000, 0], [10000, 0], [500000, 0]]))

@app.get("/")
def health():
    return {"status": "Ironclad AI Active", "features": ["IsolationForest", "Z-Score", "Benford-Heuristics"]}

@app.post("/predict")
def predict_fraud(tx: Transaction):
    try:
        risk_score = 10
        reasons = []
        is_anomaly = False

        # --- FEATURE ENGINEERING ---
        agency_name = str(tx.agency)
        encoded_agency = -1

        # Handle Unknown Agency safely
        if 'agency' in encoders:
            try:
                encoded_agency = encoders['agency'].transform([agency_name])[0]
            except:
                encoded_agency = 0 # Default to index 0 if unknown

        # --- LAYER 1: STATISTICAL OUTLIER (Z-Score) ---
        stats = data_stats.get('agency_stats', {}).get(agency_name)
        if stats and not np.isnan(stats['std']) and stats['std'] > 0:
            z_score = (tx.amount - stats['mean']) / stats['std']
            if z_score > 3:
                risk_score += 40
                reasons.append(f"Amount is {z_score:.1f}x deviations above {agency_name} average")
                is_anomaly = True
        elif tx.amount > data_stats.get('global_99th', 1000000):
             risk_score += 30
             reasons.append("Amount is in Global Top 1%")

        # --- LAYER 2: ISOLATION FOREST ---
        if api_model:
            pred = api_model.predict([[tx.amount, encoded_agency]])[0]
            if pred == -1:
                risk_score += 35
                reasons.append("AI Model detected unusual Amount/Agency combination")
                is_anomaly = True

        # --- LAYER 3: FORENSIC HEURISTICS ---
        if tx.amount > 10000 and tx.amount % 1000 == 0:
             risk_score += 15
             reasons.append("Suspiciously round number (Forensic Flag)")

        if tx.amount > 5000000: 
             risk_score += 10
             reasons.append("High Value Transaction Monitor")

        # --- LAYER 4: BENFORD'S LAW (FEATURE 5) ---
        benford_score, benford_reason = check_benfords_law(tx.amount)
        if benford_score > 0:
            risk_score += benford_score
            reasons.append(benford_reason)

        # --- LAYER 5: TIME-BASED DETECTION (FEATURE 7) ---
        time_score, time_reason = check_transaction_time(tx.transaction_time)
        if time_score > 0:
            risk_score += time_score
            reasons.append(time_reason)

        risk_score = min(99, risk_score)

        return {
            "risk_score": int(risk_score),
            "is_anomaly": is_anomaly or risk_score > 70,
            "reasons": reasons
        }

    except Exception as e:
        print(f"Prediction Error: {e}")
        traceback.print_exc() # PRINT FULL STACK TRACE TO CONSOLE
        return {"risk_score": 50, "is_anomaly": False, "reasons": ["Error in AI Engine"]}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)

